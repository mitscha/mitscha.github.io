<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Michael Tschannen</title>
  <meta name="description" content="">

  <link rel="shortcut icon" href="https://mitscha.github.io/assets/img/favicon.ico">

  <link rel="stylesheet" href="https://mitscha.github.io/assets/css/main.css">
  <link rel="canonical" href="https://mitscha.github.io/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">



    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="https://mitscha.github.io/">About</a>
        <a class="page-link" href="#news">News</a>
        <a class="page-link" href="#pubs">Publications</a>

        <!-- Pages -->
















        <!-- CV link -->
        <!-- <a class="page-link" href="https://mitscha.github.io/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Michael Tschannen</h1>
    <h5 class="post-description"></h5>
  </header>

  <article class="post-content Michael Tschannen clearfix">

  <div class="profile col one left">

      <img class="one" src="https://mitscha.github.io/assets/img/michael.jpg">


      <div class="contacticon center social">
    <!-- <a href="mailto:"><i class="fas fa-envelope"></i></a> -->

    &nbsp;&nbsp;<a href="https://scholar.google.com/citations?user=TSj_8nYAAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
    <a href="https://github.com/mitscha" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>&nbsp;
    <a href="https://www.linkedin.com/in/michael-tschannen-31119094" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>&nbsp;
    <a href="https://twitter.com/mtschannen" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>



</div>


  </div>


<p>I’m a Research Scientist at <a href="https://deepmind.google/">Google DeepMind</a> Zurich
(formerly Google Brain) broadly interested in multimodal learning for understanding and generation tasks.</p>

<p>Before that I was working on computer vision R&amp;D at <a href="https://machinelearning.apple.com/">Apple</a> Zurich for two years, and spent a year as a
postdoc at <a href="https://research.google/">Google Research</a> Zurich
(Brain Team) exploring topics in
unsupervised representation learning, generative models, and neural compression.
I completed my PhD at <a href="https://ethz.ch">ETH Zurich</a> under the supervision of
<a href="https://www.mins.ee.ethz.ch/people/show/boelcskei">Helmut Bölcskei</a> in late 2018.
Prior to that I obtained a MSc (with distinction) from <a href="https://ethz.ch">ETH Zurich</a>
and a BSc from <a href="https://www.epfl.ch">EPFL</a>, both in Electrical Engineering and
Information Technology. In fall 2017, I interned at
<a href="https://aws.amazon.com/ai/">Amazon AI</a> in Palo Alto, CA, and in fall 2018 I was
a part-time research consultant working with <a href="https://research.google/">Google Research</a> Zurich
(Brain Team).</p>

<p>Contact: mi.&lt;last name&gt;&lt;at&gt;gmail.com</p>


  </article>


    <div class="news">
  <h2 id="news">News</h2>

    <table>


      <tr>
        <td class="date">May 4, 2024</td>
        <td class="announcement">

            Check out recent code releases for GIVT (<a href="https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/givt/README.md">link</a>) and CapPa (<a href="https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/cappa/README.md">link</a>), and recent talks on CLIPPO (<a href="https://www.youtube.com/watch?v=rUwY4IvfLmQ">link</a>) and CapPa (<a href="https://neurips.cc/virtual/2023/oral/73871">link</a>).


        </td>
      </tr>

      <tr>
        <td class="date">Aug 15, 2022</td>
        <td class="announcement">

            I re-joined Google.


        </td>
      </tr>

      <tr>
        <td class="date">Oct 10, 2020</td>
        <td class="announcement">

            <a href="https://arxiv.org/abs/2006.09965">HiFiC</a> brings generative image compression
to the next level! Check out the <a href="https://hific.github.io/">demo page</a> and the
<a href="https://news.ycombinator.com/item?id=23652753">Hacker News Thread</a>.


        </td>
      </tr>

      <tr>
        <td class="date">Mar 24, 2020</td>
        <td class="announcement">

            <a href="https://arxiv.org/abs/1912.02783">Two</a> <a href="https://arxiv.org/abs/2003.10184">papers</a> accepted for presentation at CVPR 2020!


        </td>
      </tr>

      <tr>
        <td class="date">Jan 25, 2020</td>
        <td class="announcement">

            I’m happy to announce that I obtained the <a href="https://ethz.ch/en/the-eth-zurich/education/awards/eth-medal.html">ETH Medal</a> (outstanding thesis award) for my <a href="https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/322751/eth-25498.pdf">PhD thesis</a>!


        </td>
      </tr>

    </table>

</div>




    <div class="publications">
<h2 id="pubs">Publications</h2>
<p><font size="2" color=#aaa>*denotes equal contribution. See <a herf="https://scholar.google.com/citations?hl=de&user=TSj_8nYAAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> for a potentially more up-to-date list.</font></p>


  <h3 class="year">2024</h3>
  <ol class="bibliography"><li>

<div id="wan2024locca">


    <span class="title"><a href="https://arxiv.org/abs/2403.19596" target="_blank">LocCa: Visual Pretraining with Location-aware Captioners</a></span>

    <span class="author">






                Bo Wan,









              <em>Michael Tschannen</em>,









                Yongqin Xian,










                Filip Pavetic,










                Ibrahim Alabdulmohsin,










                Xiao Wang,










                André Susano Pinto,










                Andreas Steiner,










                Lucas Beyer,










                and Xiaohua Zhai





    </span>

    <span class="periodical">

      <em>arXiv:2403.19596,</em>


      2024

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="chen2024pali">


    <span class="title"><a href="https://arxiv.org/abs/2305.18565" target="_blank">PaLI-X: On scaling up a multilingual vision and language model</a></span>

    <span class="author">






                Xi Chen,










                Josip Djolonga,










                Piotr Padlewski,










                Basil Mustafa,










                Soravit Changpinyo,










                Jialin Wu,










                Carlos Riquelme Ruiz,










                Sebastian Goodman,










                Xiao Wang,










                Yi Tay,










                Siamak Shakeri,










                Mostafa Dehghani,










                Daniel Salz,










                Mario Lucic,









              <em>Michael Tschannen</em>,









                Arsha Nagrani,










                Hexiang Hu,










                Mandar Joshi,










                Bo Pang,










                Ceslee Montgomery,










                Paulina Pietrzyk,










                Marvin Ritter,










                A. J. Piergiovanni,










                Matthias Minderer,










                Filip Pavetic,










                Austin Waters,










                Gang Li,










                Ibrahim Alabdulmohsin,










                Lucas Beyer,










                Julien Amelot,










                Kenton Lee,










                Andreas Peter Steiner,










                Yang Li,










                Daniel Keysers,










                Anurag Arnab,










                Yuanzhong Xu,










                Keran Rong,










                Alexander Kolesnikov,










                Mojtaba Seyedhosseini,










                Anelia Angelova,










                Xiaohua Zhai,










                Neil Houlsby,










                and Radu Soricut





    </span>

    <span class="periodical">

      <em>In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR),</em>


      2024

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="mentzer2023finite">


    <span class="title"><a href="https://arxiv.org/abs/2309.15505" target="_blank">Finite scalar quantization: VQ-VAE made simple</a></span>

    <span class="author">






                Fabian Mentzer,










                David Minnen,










                Eirikur Agustsson,









              and <em>Michael Tschannen</em>




    </span>

    <span class="periodical">

      <em>In Proc. International Conference on Learning Representations (ICLR),</em>


      2024

    </span>


  <span class="links">








  </span>
  <span class="note">

    <a href="https://github.com/google-research/google-research/tree/master/fsq">[colab]</a>

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="stanic2024towards">


    <span class="title"><a href="https://arxiv.org/abs/2401.01974" target="_blank">Towards truly zero-shot compositional visual reasoning with LLMs as programmers</a></span>

    <span class="author">






                Aleksandar Stanić,










                Sergi Caelles,









              and <em>Michael Tschannen</em>




    </span>

    <span class="periodical">

      <em>Transactions on Machine Learning Research (TMLR),</em>


      2024

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li></ol>

  <h3 class="year">2023</h3>
  <ol class="bibliography"><li>

<div id="tschannen2023givt">


    <span class="title"><a href="https://arxiv.org/abs/2312.02116" target="_blank">GIVT: Generative Infinite-Vocabulary Transformers</a></span>

    <span class="author">





              <em>Michael Tschannen</em>,









                Cian Eastwood,










                and Fabian Mentzer





    </span>

    <span class="periodical">

      <em>arXiv:2312.02116,</em>


      2023

    </span>


  <span class="links">








  </span>
  <span class="note">


	<a href="https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/givt/README.md">[code]</a>
	<a href="https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/givt/givt_demo_colab.ipynb">[colab]</a>


  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="tschannen2024image">


    <span class="title"><a href="https://arxiv.org/abs/2306.07915" target="_blank">Image captioners are scalable vision learners too</a></span>

    <span class="author">





              <em>Michael Tschannen</em>,









                Manoj Kumar,










                Andreas Steiner,










                Xiaohua Zhai,










                Neil Houlsby,










                and Lucas Beyer





    </span>

    <span class="periodical">

      <em>In Advances in Neural Information Processing Systems (NeurIPS),</em>


      2023

    </span>


  <span class="links">








  </span>
  <span class="note">


	oral presentation
	<a href="https://neurips.cc/virtual/2023/oral/73871">[talk]</a>
	<a href="https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/cappa/README.md">[code]</a>


  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="mentzer2023m2t">


    <span class="title"><a href="https://arxiv.org/abs/2304.07313" target="_blank">M2T: Masking transformers twice for faster decoding</a></span>

    <span class="author">






                Fabian Mentzer,










                Eirikur Agustson,









              and <em>Michael Tschannen</em>




    </span>

    <span class="periodical">

      <em>In Proc. IEEE International Conference on Computer Vision (ICCV),</em>


      2023

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="dehghani2023scaling">


    <span class="title"><a href="https://arxiv.org/abs/2302.05442" target="_blank">Scaling vision transformers to 22 billion parameters</a></span>

    <span class="author">






                Mostafa Dehghani,










                Josip Djolonga,










                Basil Mustafa,










                Piotr Padlewski,










                Jonathan Heek,










                Justin Gilmer,










                Andreas Peter Steiner,










                Mathilde Caron,










                Robert Geirhos,










                Ibrahim Alabdulmohsin,










                Rodolphe Jenatton,










                Lucas Beyer,









              <em>Michael Tschannen</em>,









                Anurag Arnab,










                Xiao Wang,










                Carlos Riquelme Ruiz,










                Matthias Minderer,










                Joan Puigcerver,










                Utku Evci,










                Manoj Kumar,










                Sjoerd Steenkiste,










                Gamaleldin Fathy Elsayed,










                Aravindh Mahendran,










                Fisher Yu,










                Avital Oliver,










                Fantine Huot,










                Jasmijn Bastings,










                Mark Collier,










                Alexey A. Gritsenko,










                Vighnesh Birodkar,










                Cristina Nader Vasconcelos,










                Yi Tay,










                Thomas Mensink,










                Alexander Kolesnikov,










                Filip Pavetic,










                Dustin Tran,










                Thomas Kipf,










                Mario Lucic,










                Xiaohua Zhai,










                Daniel Keysers,










                Jeremiah J. Harmsen,










                and Neil Houlsby





    </span>

    <span class="periodical">

      <em>In Proc. International Conference on Machine Learning (ICML),</em>


      2023

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="tschannen2022image">


    <span class="title"><a href="https://arxiv.org/abs/2212.08045" target="_blank">CLIPPO: Image-and-Language Understanding from Pixels Only</a></span>

    <span class="author">





              <em>Michael Tschannen</em>,









                Basil Mustafa,










                and Neil Houlsby





    </span>

    <span class="periodical">

      <em>In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR),</em>


      2023

    </span>


  <span class="links">








  </span>
  <span class="note">


	<a href="https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/clippo/README.md">[code]</a>
	<a href="https://colab.research.google.com/github/google-research/big_vision/blob/main/big_vision/configs/proj/clippo/clippo_colab.ipynb">[colab]</a>
	<a href="https://www.youtube.com/watch?v=rUwY4IvfLmQ">[talk]</a>


  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="beyer2022flexivit">


    <span class="title"><a href="https://arxiv.org/abs/2212.08013" target="_blank">FlexiViT: One Model for All Patch Sizes</a></span>

    <span class="author">






                Lucas Beyer,










                Pavel Izmailov,










                Alexander Kolesnikov,










                Mathilde Caron,










                Simon Kornblith,










                Xiaohua Zhai,










                Matthias Minderer,









              <em>Michael Tschannen</em>,









                Ibrahim Alabdulmohsin,










                and Filip Pavetic





    </span>

    <span class="periodical">

      <em>In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR),</em>


      2023

    </span>


  <span class="links">








  </span>
  <span class="note">

    <a href="https://github.com/google-research/big_vision/blob/main/big_vision/configs/proj/flexivit/README.md">[code]</a>

  </span>

  <!-- Hidden abstract block -->

</div>
</li></ol>

  <h3 class="year">2022</h3>
  <ol class="bibliography"><li>

<div id="volokitin2022neural">


    <span class="title"><a href="https://arxiv.org/abs/2203.15401" target="_blank">Neural Face Video Compression using Multiple Views</a></span>

    <span class="author">






                Anna Volokitin,










                Stefan Brugger,










                Ali Benlalah,










                Sebastian Martin,










                Brian Amberg,









              and <em>Michael Tschannen</em>




    </span>

    <span class="periodical">

      <em>In Proc. IEEE Conf. on Computer Vision and Pattern Recognition Workshops (CVPRW),</em>


      2022

    </span>


  <span class="links">








  </span>
  <span class="note">

    Workshop and Challenge on Learned Image Compression (CLIC) Best Student Paper Award

  </span>

  <!-- Hidden abstract block -->

</div>
</li></ol>

  <h3 class="year">2021</h3>
  <ol class="bibliography"><li>

<div id="djolonga2020robustness">


    <span class="title"><a href="https://arxiv.org/abs/2007.08558" target="_blank">On Robustness and Transferability of Convolutional Neural Networks</a></span>

    <span class="author">






                Josip Djolonga*,










                Jessica Yung*,









              <em>Michael Tschannen*</em>,









                Rob Romijnders,










                Lucas Beyer,










                Alexander Kolesnikov,










                Joan Puigcerver,










                Matthias Minderer,










                Alexander D’Amour,










                Dan Moldovan,










                Sylvan Gelly,










                Neil Houlsby,










                Xiaohua Zhai,










                and Mario Lucic





    </span>

    <span class="periodical">

      <em>In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR),</em>


      2021

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="romijnders2020representation">


    <span class="title"><a href="https://arxiv.org/abs/2010.02808" target="_blank">Representation learning from videos in-the-wild: An object-centric approach</a></span>

    <span class="author">






                Rob Romijnders,










                Aravindh Mahendran,









              <em>Michael Tschannen</em>,









                Josip Djolonga,










                Marvin Ritter,










                Neil Houlsby,










                and Mario Lucic





    </span>

    <span class="periodical">

      <em>In Proc. IEEE Winter Conference on Applications of Computer Vision (WACV),</em>


      2021

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li></ol>

  <h3 class="year">2020</h3>
  <ol class="bibliography"><li>

<div id="mentzer2020high">


    <span class="title"><a href="https://arxiv.org/abs/2006.09965" target="_blank">High-Fidelity Generative Image Compression</a></span>

    <span class="author">






                Fabian Mentzer,










                George Toderici,









              <em>Michael Tschannen</em>,









                and Eirikur Agustsson





    </span>

    <span class="periodical">

      <em>In Advances in Neural Information Processing Systems (NeurIPS),</em>


      2020

    </span>


  <span class="links">








  </span>
  <span class="note">

    oral presentation

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="minderer2020automatic">


    <span class="title"><a href="https://arxiv.org/abs/2002.08822" target="_blank">Automatic shortcut removal for self-supervised representation learning</a></span>

    <span class="author">






                Matthias Minderer,










                Olivier Bachem,










                Neil Houlsby,









              and <em>Michael Tschannen</em>




    </span>

    <span class="periodical">

      <em>In Proc. International Conference on Machine Learning (ICML),</em>


      2020

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="locatello2020weaklysupervised">


    <span class="title"><a href="https://arxiv.org/abs/2002.02886" target="_blank">Weakly-supervised disentanglement without compromises</a></span>

    <span class="author">






                Francesco Locatello,










                Ben Poole,










                Gunnar Rätsch,










                Bernhard Schölkopf,










                Olivier Bachem,









              and <em>Michael Tschannen</em>




    </span>

    <span class="periodical">

      <em>In Proc. International Conference on Machine Learning (ICML),</em>


      2020

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="tschannen2019self">


    <span class="title"><a href="https://arxiv.org/abs/1912.02783" target="_blank">Self-supervised learning of video-induced visual invariances</a></span>

    <span class="author">





              <em>Michael Tschannen</em>,









                Josip Djolonga,










                Marvin Ritter,










                Aravindh Mahendran,










                Xiaohua Zhai,










                Neil Houlsby,










                Sylvain Gelly,










                and Mario Lucic





    </span>

    <span class="periodical">

      <em>In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR),</em>


      2020

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="mentzer2020learning">


    <span class="title"><a href="https://arxiv.org/abs/2003.10184" target="_blank">Learning better lossless image compression using lossy compression</a></span>

    <span class="author">






                Fabian Mentzer,










                Luc Van Gool,









              and <em>Michael Tschannen</em>




    </span>

    <span class="periodical">

      <em>In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR),</em>


      2020

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="tschannen2018mutual">


    <span class="title"><a href="https://arxiv.org/abs/1907.13625" target="_blank">On mutual information maximization for representation learning</a></span>

    <span class="author">





              <em>Michael Tschannen*</em>,









                Josip Djolonga*,










                Paul K. Rubenstein,










                Sylvain Gelly,










                and Mario Lucic





    </span>

    <span class="periodical">

      <em>In Proc. International Conference on Learning Representations (ICLR),</em>


      2020

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="locatello2019disentangling">


    <span class="title"><a href="https://arxiv.org/abs/1905.01258" target="_blank">Disentangling factors of variation using few labels</a></span>

    <span class="author">






                Francesco Locatello,









              <em>Michael Tschannen</em>,









                Stefan Bauer,










                Gunnar Rätsch,










                Bernhard Schölkopf,










                and Olivier Bachem





    </span>

    <span class="periodical">

      <em>In Proc. International Conference on Learning Representations (ICLR),</em>


      2020

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li></ol>

  <h3 class="year">2019</h3>
  <ol class="bibliography"><li>

<div id="azadi2019semantic">


    <span class="title"><a href="https://arxiv.org/abs/1911.11357" target="_blank">Semantic bottleneck scene generation</a></span>

    <span class="author">






                Samaneh Azadi,









              <em>Michael Tschannen</em>,









                Eric Tzeng,










                Sylvain Gelly,










                Trevor Darrell,










                and Mario Lucic





    </span>

    <span class="periodical">

      <em>arXiv:1911.11357,</em>


      2019

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="zhai2019visual">


    <span class="title"><a href="https://arxiv.org/abs/1910.04867" target="_blank">The visual task adaptation benchmark</a></span>

    <span class="author">






                Xiaohua Zhai,










                Joan Puigcerver,










                Alexander Kolesnikov,










                Pierre Ruyssen,










                Carlos Riquelme,










                Mario Lucic,










                Josip Djolonga,










                Andre Susano Pinto,










                Maxim Neumann,










                Alexey Dosovitskiy,










                Lucas Beyer,










                Olivier Bachem,









              <em>Michael Tschannen</em>,









                Marcin Michalski,










                Olivier Bousquet,










                Sylvain Gelly,










                and Neil Houlsby





    </span>

    <span class="periodical">

      <em>arXiv:1910.04867,</em>


      2019

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="agustsson2018generative">


    <span class="title"><a href="https://arxiv.org/abs/1804.02958" target="_blank">Generative adversarial networks for extreme learned image compression</a></span>

    <span class="author">






                Eirikur Agustsson*,









              <em>Michael Tschannen*</em>,









                Fabian Mentzer*,










                Radu Timofte,










                and Luc Van Gool





    </span>

    <span class="periodical">

      <em>In Proc. IEEE International Conference on Computer Vision (ICCV),</em>


      2019

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="mentzer2018practical">


    <span class="title"><a href="https://arxiv.org/abs/1811.12817" target="_blank">Practical full resolution learned lossless image compression</a></span>

    <span class="author">






                Fabian Mentzer,










                Eirikur Agustsson,









              <em>Michael Tschannen</em>,









                Radu Timofte,










                and Luc Van Gool





    </span>

    <span class="periodical">

      <em>In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR),</em>


      2019

    </span>


  <span class="links">








  </span>
  <span class="note">

    oral presentation

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="lucic2019high">


    <span class="title"><a href="https://arxiv.org/abs/1903.02271" target="_blank">High-fidelity image generation with fewer labels</a></span>

    <span class="author">






                Mario Lucic*,









              <em>Michael Tschannen*</em>,









                Marvin Ritter*,










                Xiaohua Zhai,










                Olivier Bachem,










                and Sylvain Gelly





    </span>

    <span class="periodical">

      <em>In Proc. International Conference on Machine Learning (ICML),</em>


      2019

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li></ol>

  <h3 class="year">2018</h3>
  <ol class="bibliography"><li>

<div id="tschannen2016noisy">


    <span class="title"><a href="https://arxiv.org/abs/1612.03450" target="_blank">Noisy subspace clustering via matching pursuits</a></span>

    <span class="author">





              <em>Michael Tschannen</em>,









                and Helmut Bölcskei





    </span>

    <span class="periodical">

      <em>IEEE Transactions on Information Theory,</em>


      2018

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="tschannen2018deep">


    <span class="title"><a href="https://arxiv.org/abs/1805.11057" target="_blank">Deep generative models for distribution-preserving lossy compression</a></span>

    <span class="author">





              <em>Michael Tschannen</em>,









                Eirikur Agustsson,










                and Mario Lucic





    </span>

    <span class="periodical">

      <em>In Advances in Neural Information Processing Systems (NeurIPS),</em>


      2018

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="tschannen2018recent">


    <span class="title"><a href="https://arxiv.org/abs/1812.05069" target="_blank">Recent advances in autoencoder-based representation learning</a></span>

    <span class="author">





              <em>Michael Tschannen</em>,









                Olivier Bachem,










                and Mario Lucic





    </span>

    <span class="periodical">

      <em>Bayesian Deep Learning Workshop at NeurIPS 2018,</em>


      2018

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="tschannen2017strassennets">


    <span class="title"><a href="http://proceedings.mlr.press/v80/tschannen18a.html" target="_blank">StrassenNets: Deep learning with a multiplication budget</a></span>

    <span class="author">





              <em>Michael Tschannen</em>,









                Aran Khanna,










                and Anima Anandkumar





    </span>

    <span class="periodical">

      <em>In Proc. International Conference on Machine Learning (ICML),</em>


      2018

    </span>


  <span class="links">








  </span>
  <span class="note">

    long oral presentation

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="furlanello2018born">


    <span class="title"><a href="http://proceedings.mlr.press/v80/furlanello18a.html" target="_blank">Born-again neural networks</a></span>

    <span class="author">






                Tommaso Furlanello,










                Zachary C. Lipton,









              <em>Michael Tschannen</em>,









                Laurent Itti,










                and Anima Anandkumar





    </span>

    <span class="periodical">

      <em>In Proc. International Conference on Machine Learning (ICML),</em>


      2018

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="mentzer2018conditional">


    <span class="title"><a href="https://arxiv.org/abs/1801.04260" target="_blank">Conditional probability models for deep image compression</a></span>

    <span class="author">






                Fabian Mentzer,










                Eirikur Agustsson,









              <em>Michael Tschannen</em>,









                Radu Timofte,










                and Luc Van Gool





    </span>

    <span class="periodical">

      <em>In Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR),</em>


      2018

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="torfason2018towards">


    <span class="title"><a href="https://arxiv.org/abs/1803.06131" target="_blank">Towards image understanding from deep compression without decoding</a></span>

    <span class="author">






                Róbert Torfason,










                Fabian Mentzer,










                Eirikur Agustsson,









              <em>Michael Tschannen</em>,









                Radu Timofte,










                and Luc Van Gool





    </span>

    <span class="periodical">

      <em>In Proc. International Conference on Learning Representations (ICLR),</em>


      2018

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="tschannen2018unsupervised">


    <span class="title"><a href="https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/322751/eth-25498.pdf" target="_blank">Unsupervised learning: Model-based clustering and learned compression</a></span>

    <span class="author">




            <em>Michael Tschannen</em>



    </span>

    <span class="periodical">

      <em>PhD thesis, ETH Zurich,</em>


      2018

    </span>


  <span class="links">








  </span>
  <span class="note">

    ETH Medal (outstanding thesis award)

  </span>

  <!-- Hidden abstract block -->

</div>
</li></ol>

  <h3 class="year">2017</h3>
  <ol class="bibliography"><li>

<div id="tschannen2016robust">


    <span class="title"><a href="https://arxiv.org/abs/1612.01103" target="_blank">Robust nonparametric nearest neighbor random process clustering</a></span>

    <span class="author">





              <em>Michael Tschannen</em>,









                and Helmut Bölcskei





    </span>

    <span class="periodical">

      <em>IEEE Transactions on Signal Processing,</em>


      2017

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="heckel2015dimensionality">


    <span class="title"><a href="https://academic.oup.com/imaiai/article/6/3/246/3070510" target="_blank">Dimensionality-reduced subspace clustering</a></span>

    <span class="author">






                Reinhard Heckel,









              <em>Michael Tschannen</em>,









                and Helmut Bölcskei





    </span>

    <span class="periodical">

      <em>Information and Inference: A Journal of the IMA,</em>


      2017

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="locatello2017unified">


    <span class="title"><a href="https://arxiv.org/abs/1702.06457" target="_blank">A unified optimization view on generalized matching pursuit and Frank-Wolfe</a></span>

    <span class="author">






                Francesco Locatello,










                Rajiv Khanna*,









              <em>Michael Tschannen*</em>,









                and Martin Jaggi





    </span>

    <span class="periodical">

      <em>In Proc. International Conference on Artificial Intelligence and Statistics (AISTATS),</em>


      2017

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="locatello2017greedy">


    <span class="title"><a href="https://arxiv.org/abs/1705.11041" target="_blank">Greedy algorithms for cone constrained optimization with convergence guarantees</a></span>

    <span class="author">






                Francesco Locatello,









              <em>Michael Tschannen</em>,









                Gunnar Rätsch,










                and Martin Jaggi





    </span>

    <span class="periodical">

      <em>In Advances in Neural Information Processing Systems (NIPS),</em>


      2017

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="agustsson2017soft">


    <span class="title"><a href="https://arxiv.org/abs/1704.00648" target="_blank">Soft-to-hard vector quantization for end-to-end learning compressible representations</a></span>

    <span class="author">






                Eirikur Agustsson,










                Fabian Mentzer,









              <em>Michael Tschannen</em>,









                Lukas Cavigelli,










                Radu Timofte,










                Luca Benini,










                and Luc Van Gool





    </span>

    <span class="periodical">

      <em>In Advances in Neural Information Processing Systems (NIPS),</em>


      2017

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="zihlmann2017convolutional">


    <span class="title"><a href="https://arxiv.org/abs/1710.06122" target="_blank">Convolutional recurrent neural networks for electrocardiogram classification</a></span>

    <span class="author">






                Martin Zihlmann,










                Dmytro Perekrestenko,









              and <em>Michael Tschannen</em>




    </span>

    <span class="periodical">

      <em>In Proc. Computing in Cardiology (CinC),</em>


      2017

    </span>


  <span class="links">








  </span>
  <span class="note">

    5th place in the PhysioNet/CinC Challenge 2017

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="tschannen2016deep">


    <span class="title"><a href="https://arxiv.org/abs/1609.07916" target="_blank">Deep structured features for semantic segmentation</a></span>

    <span class="author">





              <em>Michael Tschannen</em>,









                Lukas Cavigelli,










                Fabian Mentzer,










                Thomas Wiatowski,










                and Luca Benini





    </span>

    <span class="periodical">

      <em>In Proc. European Signal Processing Conference (EUSIPCO),</em>


      2017

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li></ol>

  <h3 class="year">2016</h3>
  <ol class="bibliography"><li>

<div id="wiatowski2016discrete">


    <span class="title"><a href="http://jmlr.org/proceedings/papers/v48/wiatowski16.html" target="_blank">Discrete deep feature extraction: A theory and new architectures</a></span>

    <span class="author">






                Thomas Wiatowski,









              <em>Michael Tschannen</em>,









                Aleksandar Stanić,










                Philipp Grohs,










                and Helmut Bölcskei





    </span>

    <span class="periodical">

      <em>In Proc. International Conference on Machine Learning (ICML),</em>


      2016

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="tschannen2016heart">


    <span class="title"><a href="http://www.cinc.org/archives/2016/pdf/162-186.pdf" target="_blank">Heart sound classification using deep structured features</a></span>

    <span class="author">





              <em>Michael Tschannen</em>,









                Thomas Kramer,










                Gian Marti,










                Matthias Heinzmann,










                and Thomas Wiatowski





    </span>

    <span class="periodical">

      <em>In Proc. Computing in Cardiology (CinC),</em>


      2016

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="tschannen2015regression">


    <span class="title"><a href="http://www.sciencedirect.com/science/article/pii/S1361841516000232" target="_blank">Regression forest-based automatic estimation of the articular margin plane for shoulder prosthesis planning</a></span>

    <span class="author">





              <em>Michael Tschannen</em>,









                Lazaros Vlachopoulos,










                Christian Gerber,










                Gábor Székely,










                and Philipp Fürnstahl





    </span>

    <span class="periodical">

      <em>Medical Image Analysis,</em>


      2016

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li></ol>

  <h3 class="year">2015</h3>
  <ol class="bibliography"><li>

<div id="tschannen2015nonparametric">


    <span class="title"><a href="https://arxiv.org/abs/1504.05059" target="_blank">Nonparametric nearest neighbor random process clustering</a></span>

    <span class="author">





              <em>Michael Tschannen</em>,









                and Helmut Bölcskei





    </span>

    <span class="periodical">

      <em>In Proc. IEEE International Symposium on Information Theory (ISIT),</em>


      2015

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li></ol>

  <h3 class="year">2014</h3>
  <ol class="bibliography"><li>

<div id="heckel_subspace_2014">


    <span class="title"><a href="https://arxiv.org/abs/1404.6818" target="_blank">Subspace clustering of dimensionality-reduced data</a></span>

    <span class="author">






                Reinhard Heckel,









              <em>Michael Tschannen</em>,









                and Helmut Bölcskei





    </span>

    <span class="periodical">

      <em>In Proc. IEEE International Symposium on Information Theory (ISIT),</em>


      2014

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li>
<li>

<div id="tschannen2014dimensionality">


    <span class="title"><a href="https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/155169/eth-47901-01.pdf" target="_blank">Dimensionality reduction for sparse subspace clustering</a></span>

    <span class="author">




            <em>Michael Tschannen</em>



    </span>

    <span class="periodical">

      <em>MS thesis, ETH Zurich,</em>


      2014

    </span>


  <span class="links">








  </span>
  <span class="note">

    ETH Medal (outstanding thesis award) and the SEW Eurodrive Foundation Graduate Award

  </span>

  <!-- Hidden abstract block -->

</div>
</li></ol>

  <h3 class="year">2013</h3>
  <ol class="bibliography"><li>

<div id="deluca2013learning">


    <span class="title"><a href="http://link.springer.com/chapter/10.1007/978-3-642-40811-3_65" target="_blank">A learning-based approach for fast and robust vessel tracking in long ultrasound sequences</a></span>

    <span class="author">






                Valeria De Luca,









              <em>Michael Tschannen</em>,









                Gábor Székely,










                and Christine Tanner





    </span>

    <span class="periodical">

      <em>In Medical Image Computing and Computer-Assisted Intervention (MICCAI),</em>


      2013

    </span>


  <span class="links">








  </span>
  <span class="note">

  </span>

  <!-- Hidden abstract block -->

</div>
</li></ol>

</div>



</div>

      </div>
    </div>

    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="https://mitscha.github.io/assets/js/common.js"></script>





<!-- Include custom icon fonts -->
<link rel="stylesheet" href="https://mitscha.github.io/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="https://mitscha.github.io/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
